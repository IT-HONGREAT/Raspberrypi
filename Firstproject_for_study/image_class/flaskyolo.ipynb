{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flaskyolo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxV1i7Rt7DqY"
      },
      "source": [
        "#Yolov3 Object Detection with Flask and Tensorflow 2.0 (APIs and Detections)\n",
        "\n",
        "Yolov3 is an algorithm that uses deep convolutional neural networks to perform object detection. This repository implements Yolov3 using TensorFlow 2.0 and creates two easy-to-use APIs that you can integrate into web or mobile applications. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzMCnhzF6dS0"
      },
      "source": [
        "# yolov3\n",
        "!mkdir weights\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights -O weights/yolov3.weights\n",
        "\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg -O weights/yolov3.cfg\n",
        "\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names -O weights/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKtzBKdT7QxC"
      },
      "source": [
        "#Building a simple Keras + deep learning REST API\n",
        "\n",
        "In this tutorial, we will present a simple method to take a Keras model and deploy it as a REST API.\n",
        "\n",
        "The examples covered in this post will serve as a template/starting point for building your own deep learning APIs â€” you will be able to extend the code and customize it based on how scalable and robust your API endpoint needs to be.\n",
        "\n",
        "Specifically, we will learn:\n",
        "\n",
        "How to (and how not to) load a Keras model into memory so it can be efficiently used for inference\n",
        "How to use the Flask web framework to create an endpoint for our API\n",
        "How to make predictions using our model, JSON-ify them, and return the results to the client\n",
        "How to call our Keras REST API using both cURL and Python\n",
        "By the end of this tutorial you'll have a good understanding of the components (in their simplest form) that go into a creating Keras REST API.\n",
        "\n",
        "Feel free to use the code presented in this guide as a starting point for your own deep learning REST API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aACBD4pY7Zu4"
      },
      "source": [
        "#Configuring your development environment\n",
        "\n",
        "We'll be making the assumption that Keras is already configured and installed on your machine. If not, please ensure you install Keras using the official install instructions.\n",
        "\n",
        "From there, we'll need to install Flask (and its associated dependencies), a Python web framework, so we can build our API endpoint. We'll also need requests so we can consume our API as well.\n",
        "\n",
        "The relevant pip install commands are listed below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQIgqCZz7F7G"
      },
      "source": [
        "!pip install flask gevent requests pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khspeLvo8HjD"
      },
      "source": [
        "#CREATE A Procfile : Create a file with name Procfile and paste content below line in it into it\n",
        "\n",
        "\n",
        "\n",
        "web: gunicorn app:app"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEQXcMHWC8IJ"
      },
      "source": [
        "procfile = 'web: gunicorn app:app'\n",
        "procfiles= open(\"/content/Procfile\",\"w\")\n",
        "procfiles.write(procfile)\n",
        "procfiles.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atj2zKWg8B26"
      },
      "source": [
        "#INSTALL FLASK AND NGROK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x9zzwu78DiS"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yLwdO2KJyeN"
      },
      "source": [
        "#Build front end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj20YhHlJ0c9"
      },
      "source": [
        "a = '''\n",
        "<!doctype html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "<link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\">\n",
        "<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js\" type=\"text/javascript\"></script>\n",
        "<script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\" type=\"text/javascript\"></script>\n",
        "  <title>Image Recognition Server</title>\n",
        "  <body class style=\"margin:10px;padding:10px\">\n",
        "    <div class=\"page-header\" id=\"banner\">\n",
        "      <div class=\"row\">\n",
        "        <div class=\"col-lg-8 col-md-7 col-sm-6\">\n",
        "          <h3>Image Recognition Server</h3>\n",
        "          <p class=\"lead\">Upload the image?</p>\n",
        "        </div>\n",
        "      </div>\n",
        "      <form action=\"\" method=post enctype=multipart/form-data>\n",
        "        <input type=file name=file>\n",
        "        <input type=submit value=Upload>\n",
        "    </form>\n",
        "    </div>\n",
        "    <p style=\"margin-bottom:2cm;\"></p>\n",
        "    <div class=\"row\">\n",
        "        <div class=\"col-lg-4\">\n",
        "          <div class=\"page-header\">\n",
        "            <h3 id=\"tables\">Result</h3>\n",
        "          </div>\n",
        "          <div class=\"bs-component\">\n",
        "            <table class=\"table table-hover\">\n",
        "                <tr class=\"table-active\">\n",
        "                 \n",
        "                  <th scope=\"col\">Predict</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                         <td> <img src=\"data:image/png;base64,{{ user_image }}\"> </td>\n",
        "                         \n",
        "                  </tr>\n",
        "            </table> \n",
        "        </div>\n",
        "      </div>\n",
        "  </body>\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8HtmLB4CzX6"
      },
      "source": [
        "#Build directory structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKwLSHvH3j-M"
      },
      "source": [
        "!mkdir '/content/templates'\n",
        "!mkdir '/content/uploads'\n",
        "!mkdir '/content/detections'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJC9AprzCHfa"
      },
      "source": [
        "Html_file= open(\"/content/templates/index.html\",\"w\")\n",
        "Html_file.write(a)\n",
        "Html_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUt5GZQ7_96I"
      },
      "source": [
        "#Running the Flask App and Using the APIs\n",
        "\n",
        "Now you can run a Flask application to create two object detections APIs in order to get detections through REST endpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eggpus3WeWfB"
      },
      "source": [
        "!pip install jsonpickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXWpcuwL_-28"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "from flask import Flask, request, Response, jsonify, render_template\n",
        "import jsonpickle\n",
        "#import binascii\n",
        "import io as StringIO\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import io\n",
        "import json\n",
        "from PIL import Image\n",
        "import base64\n",
        "# construct the argument parse and parse the arguments\n",
        "\n",
        "confthres = 0.3\n",
        "nmsthres = 0.1\n",
        "yolo_path = './'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_labels(labels_path):\n",
        "    # load the COCO class labels our YOLO model was trained on\n",
        "    #labelsPath = os.path.sep.join([yolo_path, \"yolo_v3/coco.names\"])\n",
        "    lpath=os.path.sep.join([yolo_path, labels_path])\n",
        "    LABELS = open(lpath).read().strip().split(\"\\n\")\n",
        "    return LABELS\n",
        "\n",
        "def get_colors(LABELS):\n",
        "    # initialize a list of colors to represent each possible class label\n",
        "    np.random.seed(42)\n",
        "    COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")\n",
        "    return COLORS\n",
        "\n",
        "def get_weights(weights_path):\n",
        "    # derive the paths to the YOLO weights and model configuration\n",
        "    weightsPath = os.path.sep.join([yolo_path, weights_path])\n",
        "    return weightsPath\n",
        "\n",
        "def get_config(config_path):\n",
        "    configPath = os.path.sep.join([yolo_path, config_path])\n",
        "    return configPath\n",
        "\n",
        "def load_model(configpath,weightspath):\n",
        "    # load our YOLO object detector trained on COCO dataset (80 classes)\n",
        "    print(\"[INFO] loading YOLO from disk...\")\n",
        "    net = cv2.dnn.readNetFromDarknet(configpath, weightspath)\n",
        "    return net\n",
        "\n",
        "\n",
        "def image_to_byte_array(image:Image):\n",
        "  imgByteArr = io.BytesIO()\n",
        "  image.save(imgByteArr, format='PNG')\n",
        "  imgByteArr = imgByteArr.getvalue()\n",
        "  return imgByteArr\n",
        "\n",
        "\n",
        "def get_predection(image,net,LABELS,COLORS):\n",
        "    (H, W) = image.shape[:2]\n",
        "\n",
        "    # determine only the *output* layer names that we need from YOLO\n",
        "    ln = net.getLayerNames()\n",
        "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    # construct a blob from the input image and then perform a forward\n",
        "    # pass of the YOLO object detector, giving us our bounding boxes and\n",
        "    # associated probabilities\n",
        "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
        "                                 swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    start = time.time()\n",
        "    layerOutputs = net.forward(ln)\n",
        "    print(layerOutputs)\n",
        "    end = time.time()\n",
        "\n",
        "    # show timing information on YOLO\n",
        "    print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))\n",
        "\n",
        "    # initialize our lists of detected bounding boxes, confidences, and\n",
        "    # class IDs, respectively\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    classIDs = []\n",
        "\n",
        "    # loop over each of the layer outputs\n",
        "    for output in layerOutputs:\n",
        "        # loop over each of the detections\n",
        "        for detection in output:\n",
        "            # extract the class ID and confidence (i.e., probability) of\n",
        "            # the current object detection\n",
        "            scores = detection[5:]\n",
        "            # print(scores)\n",
        "            classID = np.argmax(scores)\n",
        "            # print(classID)\n",
        "            confidence = scores[classID]\n",
        "\n",
        "            # filter out weak predictions by ensuring the detected\n",
        "            # probability is greater than the minimum probability\n",
        "            if confidence > confthres:\n",
        "                # scale the bounding box coordinates back relative to the\n",
        "                # size of the image, keeping in mind that YOLO actually\n",
        "                # returns the center (x, y)-coordinates of the bounding\n",
        "                # box followed by the boxes' width and height\n",
        "                box = detection[0:4] * np.array([W, H, W, H])\n",
        "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                # use the center (x, y)-coordinates to derive the top and\n",
        "                # and left corner of the bounding box\n",
        "                x = int(centerX - (width / 2))\n",
        "                y = int(centerY - (height / 2))\n",
        "\n",
        "                # update our list of bounding box coordinates, confidences,\n",
        "                # and class IDs\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "                classIDs.append(classID)\n",
        "\n",
        "    # apply non-maxima suppression to suppress weak, overlapping bounding\n",
        "    # boxes\n",
        "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, confthres,\n",
        "                            nmsthres)\n",
        "\n",
        "    # ensure at least one detection exists\n",
        "    if len(idxs) > 0:\n",
        "        # loop over the indexes we are keeping\n",
        "        for i in idxs.flatten():\n",
        "            # extract the bounding box coordinates\n",
        "            (x, y) = (boxes[i][0], boxes[i][1])\n",
        "            (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "            # draw a bounding box rectangle and label on the image\n",
        "            color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
        "            print(boxes)\n",
        "            print(classIDs)\n",
        "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
        "    return image\n",
        "\n",
        "\n",
        "labelsPath=\"weights/coco.names\"\n",
        "cfgpath=\"weights/yolov3.cfg\"\n",
        "wpath=\"weights/yolov3.weights\"\n",
        "Lables=get_labels(labelsPath)\n",
        "CFG=get_config(cfgpath)\n",
        "Weights=get_weights(wpath)\n",
        "nets=load_model(CFG,Weights)\n",
        "Colors=get_colors(Lables)\n",
        "# Initialize the Flask application\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  \n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "# route http posts to this method\n",
        "@app.route('/', methods=['POST'])\n",
        "def main():\n",
        "    # load our input image and grab its spatial dimensions\n",
        "    #image = cv2.imread(\"/content/rsz_namibia_will_burrard_lucas_wwf_us_1.jpg\")\n",
        "    img = request.files[\"file\"].read()\n",
        "    img = Image.open(io.BytesIO(img))\n",
        "    npimg=np.array(img)\n",
        "    image=npimg.copy()\n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    res=get_predection(image,nets,Lables,Colors)\n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    image=cv2.cvtColor(res,cv2.COLOR_BGR2RGB)\n",
        "    #image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    # show the output image\n",
        "    #cv2_imshow(res)\n",
        "    #cv2.waitKey()\n",
        "    #cv2.imwrite(\"filename.png\", res)\n",
        "    np_img=Image.fromarray(image)\n",
        "    img_encoded=image_to_byte_array(np_img)  \n",
        "    base64_bytes = base64.b64encode(img_encoded).decode(\"utf-8\")    \n",
        "    #return jsonify({'status': True, 'image': image})      \n",
        "    return render_template('index.html', user_image=base64_bytes)\n",
        "\n",
        "    # start flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}